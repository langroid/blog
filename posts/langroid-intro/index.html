<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Langroid Intro | Langroid Blog</title><meta name=keywords content><meta name=description content="Langroid: Harness LLMs with Multi-Agent Programming The LLM Opportunity Given the remarkable abilities of recent Large Language Models (LLMs), there is an unprecedented opportunity to build intelligent applications powered by this transformative technology. The top question for any enterprise is: how best to harness the power of LLMs for complex applications? For technical and practical reasons, building LLM-powered applications is not as simple as throwing a task at an LLM-system and expecting it to do it."><meta name=author content="Prasad Chalasani"><link rel=canonical href=https://langroid.github.io/blog/posts/langroid-intro/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/blog/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://langroid.github.io/blog/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://langroid.github.io/blog/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://langroid.github.io/blog/favicon-32x32.png><link rel=apple-touch-icon href=https://langroid.github.io/blog/apple-touch-icon.png><link rel=mask-icon href=https://langroid.github.io/blog/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Langroid Intro"><meta property="og:description" content="Langroid: Harness LLMs with Multi-Agent Programming The LLM Opportunity Given the remarkable abilities of recent Large Language Models (LLMs), there is an unprecedented opportunity to build intelligent applications powered by this transformative technology. The top question for any enterprise is: how best to harness the power of LLMs for complex applications? For technical and practical reasons, building LLM-powered applications is not as simple as throwing a task at an LLM-system and expecting it to do it."><meta property="og:type" content="article"><meta property="og:url" content="https://langroid.github.io/blog/posts/langroid-intro/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-09-02T21:34:34-04:00"><meta property="article:modified_time" content="2023-09-02T21:34:34-04:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Langroid Intro"><meta name=twitter:description content="Langroid: Harness LLMs with Multi-Agent Programming The LLM Opportunity Given the remarkable abilities of recent Large Language Models (LLMs), there is an unprecedented opportunity to build intelligent applications powered by this transformative technology. The top question for any enterprise is: how best to harness the power of LLMs for complex applications? For technical and practical reasons, building LLM-powered applications is not as simple as throwing a task at an LLM-system and expecting it to do it."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://langroid.github.io/blog/posts/"},{"@type":"ListItem","position":3,"name":"Langroid Intro","item":"https://langroid.github.io/blog/posts/langroid-intro/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Langroid Intro","name":"Langroid Intro","description":"Langroid: Harness LLMs with Multi-Agent Programming The LLM Opportunity Given the remarkable abilities of recent Large Language Models (LLMs), there is an unprecedented opportunity to build intelligent applications powered by this transformative technology. The top question for any enterprise is: how best to harness the power of LLMs for complex applications? For technical and practical reasons, building LLM-powered applications is not as simple as throwing a task at an LLM-system and expecting it to do it.","keywords":[],"articleBody":"Langroid: Harness LLMs with Multi-Agent Programming The LLM Opportunity Given the remarkable abilities of recent Large Language Models (LLMs), there is an unprecedented opportunity to build intelligent applications powered by this transformative technology. The top question for any enterprise is: how best to harness the power of LLMs for complex applications? For technical and practical reasons, building LLM-powered applications is not as simple as throwing a task at an LLM-system and expecting it to do it.\nLangroid’s Multi-Agent Programming Framework Effectively leveraging LLMs at scale requires a principled programming framework. In particular, there is often a need to maintain multiple LLM conversations, each instructed in different ways, and “responsible” for different aspects of a task.\nAn agent is a convenient abstraction that encapsulates LLM conversation state, along with access to long-term memory (vector-stores) and tools (a.k.a functions or plugins). Thus a Multi-Agent Programming framework is a natural fit for complex LLM-based applications.\nLangroid is the first Python LLM-application framework that was explicitly designed with Agents as first-class citizens, and Multi-Agent Programming as the core design principle. The framework is inspired by ideas from the Actor Framework.\nLangroid allows an intuitive definition of agents, tasks and task-delegation among agents. There is a principled mechanism to orchestrate multi-agent collaboration. Agents act as message-transformers, and take turns responding to (and transforming) the current message. The architecture is lightweight, transparent, flexible, and allows other types of orchestration to be implemented. Besides Agents, Langroid also provides simple ways to directly interact with\nLLMs and vector-stores.\nHighlights Agents as first-class citizens: The Agent class encapsulates LLM conversation state, and optionally a vector-store and tools. Agents are a core abstraction in Langroid; Agents act as message transformers, and by default provide 3 responder methods, one corresponding to each entity: LLM, Agent, User. Tasks: A Task class wraps an Agent, gives the agent instructions (or roles, or goals), manages iteration over an Agent’s responder methods, and orchestrates multi-agent interactions via hierarchical, recursive task-delegation. The Task.run() method has the same type-signature as an Agent’s responder’s methods, and this is key to how a task of an agent can delegate to other sub-tasks: from the point of view of a Task, sub-tasks are simply additional responders, to be used in a round-robin fashion after the agent’s own responders. Modularity, Reusabilily, Loose coupling: The Agent and Task abstractions allow users to design Agents with specific skills, wrap them in Tasks, and combine tasks in a flexible way. LLM Support: Langroid supports OpenAI LLMs including GPT-3.5-Turbo, GPT-4. Caching of LLM prompts, responses: Langroid by default uses Redis for caching. Caching with Momento is also supported. Vector-stores: Qdrant and Chroma are currently supported. Vector stores allow for Retrieval-Augmented-Generaation (RAG). Grounding and source-citation: Access to external documents via vector-stores allows for grounding and source-citation. Observability, Logging, Lineage: Langroid generates detailed logs of multi-agent interactions and maintains provenance/lineage of messages, so that you can trace back the origin of a message. Tools/Plugins/Function-calling: Langroid supports OpenAI’s recently released function calling feature. In addition, Langroid has its own native equivalent, which we call tools (also known as “plugins” in other contexts). Function calling and tools have the same developer-facing interface, implemented using Pydantic, which makes it very easy to define tools/functions and enable agents to use them. Benefits of using Pydantic are that you never have to write complex JSON specs for function calling, and when the LLM hallucinates malformed JSON, the Pydantic error message is sent back to the LLM so it can fix it! Test code snippets from langroid.language_models.base import LLMMessage, Role msg = LLMMessage( content=\"what is the capital of Bangladesh?\", role=Role.USER, ) Test math notation A nice equation is $e^{i\\pi} + 1 = 0$, which is known as Euler’s identity. Here is a cool equation too, (e = mc^2), and in display mode:\n[ e = mc^2 ]\nOr this way\n$$ e = mc^2 $$\n","wordCount":"642","inLanguage":"en","datePublished":"2023-09-02T21:34:34-04:00","dateModified":"2023-09-02T21:34:34-04:00","author":{"@type":"Person","name":"Prasad Chalasani"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://langroid.github.io/blog/posts/langroid-intro/"},"publisher":{"@type":"Organization","name":"Langroid Blog","logo":{"@type":"ImageObject","url":"https://langroid.github.io/blog/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://langroid.github.io/blog accesskey=h title="Langroid Blog (Alt + H)">Langroid Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Langroid Intro</h1><div class=post-meta><span title='2023-09-02 21:34:34 -0400 -0400'>September 2, 2023</span>&nbsp;·&nbsp;Prasad Chalasani</div></header><div class=post-content><h1 id=langroid-harness-llms-with-multi-agent-programming>Langroid: Harness LLMs with Multi-Agent Programming<a hidden class=anchor aria-hidden=true href=#langroid-harness-llms-with-multi-agent-programming>#</a></h1><h2 id=the-llm-opportunity>The LLM Opportunity<a hidden class=anchor aria-hidden=true href=#the-llm-opportunity>#</a></h2><p>Given the remarkable abilities of recent Large Language Models (LLMs), there
is an unprecedented opportunity to build intelligent applications powered by
this transformative technology. The top question for any enterprise is: how
best to harness the power of LLMs for complex applications? For technical and
practical reasons, building LLM-powered applications is not as simple as
throwing a task at an LLM-system and expecting it to do it.</p><h2 id=langroids-multi-agent-programming-framework>Langroid&rsquo;s Multi-Agent Programming Framework<a hidden class=anchor aria-hidden=true href=#langroids-multi-agent-programming-framework>#</a></h2><p>Effectively leveraging LLMs at scale requires a <em>principled programming
framework</em>. In particular, there is often a need to maintain multiple LLM
conversations, each instructed in different ways, and &ldquo;responsible&rdquo; for
different aspects of a task.</p><p>An <em>agent</em> is a convenient abstraction that encapsulates LLM conversation
state, along with access to long-term memory (vector-stores) and tools (a.k.a functions
or plugins). Thus a <strong>Multi-Agent Programming</strong> framework is a natural fit
for complex LLM-based applications.</p><blockquote><p>Langroid is the first Python LLM-application framework that was explicitly
designed with Agents as first-class citizens, and Multi-Agent Programming
as the core design principle. The framework is inspired by ideas from the
<a href=https://en.wikipedia.org/wiki/Actor_model>Actor Framework</a>.</p></blockquote><p>Langroid allows an intuitive definition of agents, tasks and task-delegation
among agents. There is a principled mechanism to orchestrate multi-agent
collaboration. Agents act as message-transformers, and take turns responding to (and
transforming) the current message. The architecture is lightweight, transparent,
flexible, and allows other types of orchestration to be implemented.
Besides Agents, Langroid also provides simple ways to directly interact with<br>LLMs and vector-stores.</p><h2 id=highlights>Highlights<a hidden class=anchor aria-hidden=true href=#highlights>#</a></h2><ul><li><strong>Agents as first-class citizens:</strong> The <code>Agent</code> class encapsulates LLM conversation state,
and optionally a vector-store and tools. Agents are a core abstraction in Langroid;
Agents act as <em>message transformers</em>, and by default provide 3 <em>responder</em> methods, one corresponding to each
entity: LLM, Agent, User.</li><li><strong>Tasks:</strong> A Task class wraps an Agent, gives the agent instructions (or roles, or goals),
manages iteration over an Agent&rsquo;s responder methods,
and orchestrates multi-agent interactions via hierarchical, recursive
task-delegation. The <code>Task.run()</code> method has the same
type-signature as an Agent&rsquo;s responder&rsquo;s methods, and this is key to how
a task of an agent can delegate to other sub-tasks: from the point of view of a Task,
sub-tasks are simply additional responders, to be used in a round-robin fashion
after the agent&rsquo;s own responders.</li><li><strong>Modularity, Reusabilily, Loose coupling:</strong> The <code>Agent</code> and <code>Task</code> abstractions allow users to design
Agents with specific skills, wrap them in Tasks, and combine tasks in a flexible way.</li><li><strong>LLM Support</strong>: Langroid supports OpenAI LLMs including GPT-3.5-Turbo,
GPT-4.</li><li><strong>Caching of LLM prompts, responses:</strong> Langroid by default uses <a href=https://redis.com/try-free/>Redis</a> for caching.
Caching with <a href=https://www.gomomento.com/>Momento</a> is also supported.</li><li><strong>Vector-stores</strong>: <a href=https://qdrant.tech/>Qdrant</a> and <a href=https://www.trychroma.com/>Chroma</a> are currently supported.
Vector stores allow for Retrieval-Augmented-Generaation (RAG).</li><li><strong>Grounding and source-citation:</strong> Access to external documents via vector-stores
allows for grounding and source-citation.</li><li><strong>Observability, Logging, Lineage:</strong> Langroid generates detailed logs of multi-agent interactions and
maintains provenance/lineage of messages, so that you can trace back
the origin of a message.</li><li><strong>Tools/Plugins/Function-calling</strong>: Langroid supports OpenAI&rsquo;s recently
released <a href=https://platform.openai.com/docs/guides/gpt/function-calling>function calling</a>
feature. In addition, Langroid has its own native equivalent, which we
call <strong>tools</strong> (also known as &ldquo;plugins&rdquo; in other contexts). Function
calling and tools have the same developer-facing interface, implemented
using <a href=https://docs.pydantic.dev/latest/>Pydantic</a>,
which makes it very easy to define tools/functions and enable agents
to use them. Benefits of using Pydantic are that you never have to write
complex JSON specs for function calling, and when the LLM
hallucinates malformed JSON, the Pydantic error message is sent back to
the LLM so it can fix it!</li></ul><h2 id=test-code-snippets>Test code snippets<a hidden class=anchor aria-hidden=true href=#test-code-snippets>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langroid.language_models.base <span style=color:#f92672>import</span> LLMMessage, Role
</span></span><span style=display:flex><span>msg <span style=color:#f92672>=</span> LLMMessage(
</span></span><span style=display:flex><span>        content<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;what is the capital of Bangladesh?&#34;</span>,
</span></span><span style=display:flex><span>        role<span style=color:#f92672>=</span>Role<span style=color:#f92672>.</span>USER,
</span></span><span style=display:flex><span>      )
</span></span></code></pre></div><h2 id=test-math-notation>Test math notation<a hidden class=anchor aria-hidden=true href=#test-math-notation>#</a></h2><p>A nice equation is $e^{i\pi} + 1 = 0$, which is known as Euler&rsquo;s identity.
Here is a cool equation too, (e = mc^2), and in display mode:</p><p>[
e = mc^2
]</p><p>Or this way</p><p>$$
e = mc^2
$$</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://langroid.github.io/blog>Langroid Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>